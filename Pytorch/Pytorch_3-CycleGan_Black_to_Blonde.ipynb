{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "from argparse import ArgumentParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as tranforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torchsummary import summary\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd\n",
    "from IPython.display import Image as ImageDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = r'C:\\Users\\EmincanY\\Desktop\\Pythorch\\GAN\\img_celeba\\images'\n",
    "attributes_file = r'C:\\Users\\EmincanY\\Desktop\\Pythorch\\GAN\\img_celeba\\list_attr_celeba.csv'\n",
    "output_dir = r'C:\\Users\\EmincanY\\Desktop\\Pythorch\\GAN\\img_celeba\\preprocessed_dataset_celeba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
       "0  000001.jpg                -1                1           1               -1   \n",
       "1  000002.jpg                -1               -1          -1                1   \n",
       "2  000003.jpg                -1               -1          -1               -1   \n",
       "3  000004.jpg                -1               -1           1               -1   \n",
       "4  000005.jpg                -1                1           1               -1   \n",
       "\n",
       "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  Sideburns  Smiling  \\\n",
       "0    -1     -1        -1        -1          -1  ...         -1        1   \n",
       "1    -1     -1        -1         1          -1  ...         -1        1   \n",
       "2    -1     -1         1        -1          -1  ...         -1       -1   \n",
       "3    -1     -1        -1        -1          -1  ...         -1       -1   \n",
       "4    -1     -1         1        -1          -1  ...         -1       -1   \n",
       "\n",
       "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
       "0              1         -1                 1           -1                 1   \n",
       "1             -1         -1                -1           -1                -1   \n",
       "2             -1          1                -1           -1                -1   \n",
       "3              1         -1                 1           -1                 1   \n",
       "4             -1         -1                -1           -1                 1   \n",
       "\n",
       "   Wearing_Necklace  Wearing_Necktie  Young  \n",
       "0                -1               -1      1  \n",
       "1                -1               -1      1  \n",
       "2                -1               -1      1  \n",
       "3                 1               -1      1  \n",
       "4                -1               -1      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(attributes_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blackHairFemale = df.loc[df['Black_Hair' ] == 1 & (df['Male'] == -1)].sample(1000)\n",
    "df_blondHairFemale = df.loc[df['Blond_Hair' ] == 1 & (df['Male'] == -1)].sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "domainA , domainB = [] , []\n",
    "\n",
    "for index, row in df_blackHairFemale.iterrows():\n",
    "    domainA.append(row['image_id'])\n",
    "\n",
    "for index, row in df_blondHairFemale.iterrows():\n",
    "    domainB.append(row['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train , A_test , = train_test_split(domainA , test_size = 0.01 , random_state = 53)\n",
    "B_train , B_test , = train_test_split(domainB , test_size = 0.01 , random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in A 990 and B 990\n"
     ]
    }
   ],
   "source": [
    "N = min(len(A_train) , len(B_train))\n",
    "A_train = A_train[:N]\n",
    "B_train = B_train[:N]\n",
    "\n",
    "print(f'Images in A {len(A_train)} and B {len(B_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in A 10 and B 10\n"
     ]
    }
   ],
   "source": [
    "N = min(len(A_test) , len(B_test))\n",
    "A_test = A_test[:N]\n",
    "B_test = B_test[:N]\n",
    "\n",
    "print(f'Images in A {len(A_test)} and B {len(B_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train_dir = os.path.join(output_dir , 'train/A')\n",
    "B_train_dir = os.path.join(output_dir , 'train/B')\n",
    "\n",
    "os.makedirs(A_train_dir , exist_ok = True) # Creating locations.\n",
    "os.makedirs(B_train_dir , exist_ok = True)\n",
    "\n",
    "for imageA , imageB in zip(A_train , B_train):\n",
    "    shutil.copy(os.path.join(image_dir,imageA) , os.path.join(A_train_dir , imageA))\n",
    "    shutil.copy(os.path.join(image_dir,imageB) , os.path.join(B_train_dir , imageB))\n",
    "\n",
    "A_test_dir = os.path.join(output_dir,'test/A')\n",
    "B_test_dir = os.path.join(output_dir,'test/B')\n",
    "\n",
    "os.makedirs(A_test_dir , exist_ok = True)\n",
    "os.makedirs(B_test_dir , exist_ok = True)\n",
    "\n",
    "for imageA , imageB in zip(A_test , B_test):\n",
    "    shutil.copy(os.path.join(image_dir, imageA) , os.path.join(A_test_dir , imageA))\n",
    "    shutil.copy(os.path.join(image_dir, imageB) , os.path.join(B_test_dir , imageB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImaageDataSet(Dataset):\n",
    "    def __init__(self , root , transforms_ = None , unaligned = False , mode = 'train'):\n",
    "        self.transform = tranforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "        \n",
    "        self.files_A = sorted(glob.glob(os.path.join(root , f'{mode}/A') + '/*.*')) # self.files_A = sorted(glob.glob(os.path.join(root, '%s/A' % mode) + '/*.*'))\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root , f'{mode}/B') + '/*.*'))\n",
    "    \n",
    "    def __getitem__(self, index) : \n",
    "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
    "        \n",
    "        if self.unaligned :\n",
    "            item_B = self.transform(Image.open(self.files_B[random.randing(0, len(self.files_B) - 1)]))\n",
    "        else :\n",
    "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n",
    "        return {'A' : item_A , 'B' : item_B}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A) , len(self.files_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-17-19-21-04.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self , in_features) :\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        conv_block = [ nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features , in_features , 3),\n",
    "                      nn.InstanceNorm2d(in_features),\n",
    "                      nn.ReLU(inplace = True),\n",
    "                      nn.ReflectionPad2d(i),\n",
    "                      nn.Conv2d(in_features, in_features , 3),\n",
    "                      nn.InstanceNorm2d(in_features)\n",
    "                      ]\n",
    "        \n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "        \n",
    "        def forward(self, x) : \n",
    "            return x + self.conv_block(x)\n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc , output_nc , n_residual_blocks = 9):\n",
    "        super(Generator , self).__init__()\n",
    "        \n",
    "        # Initial convolution block\n",
    "        model = [ nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc , 64 , 7),\n",
    "                 nn.InstanceNorm2d(64),\n",
    "                 nn.ReLU(inplace = True)\n",
    "                 ]\n",
    "        \n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.Conv2d(in_features , out_features , 3 , stride = 2 , padding = 1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                      ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "        \n",
    "        # Residual Blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "            \n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.ConvTranspose2d(in_features , out_features , 3 , stride = 2 , padding = 1 , output_padding = 1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace = True)  \n",
    "                      ]\n",
    "            in_features = out_features \n",
    "            out_features = in_features // 2\n",
    "        \n",
    "        # Output Layer\n",
    "        model += [   nn.ReflectionPad2d(3),\n",
    "                     nn.Conv2d(64 , output_nc , 7),\n",
    "                     nn.Tanh()   \n",
    "                  ]\n",
    "        self.model = nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-17-19-52-40.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator , self).__init__()\n",
    "        \n",
    "        # A bunch of convolutions one after another\n",
    "        model = [   nn.Conv2d(input_nc , 64 , 4 , stride = 2, padding = 1),\n",
    "                    nn.LeakyReLU(0.2, inplace = True)]\n",
    "        \n",
    "        model += [  nn.Conv2d(64 , 128, 4 , stride = 2 , padding = 1) ,\n",
    "                    nn.LeakyReLU(0.2 , inplace = True)]\n",
    "        \n",
    "        model += [  nn.Conv2d(128, 256 , 4 , stride = 2 , padding = 1),\n",
    "                    nn.InstanceNorm2d(256),\n",
    "                    nn.LeakyReLU(0.2,inplae = True)]\n",
    "        \n",
    "        model += [  nn.Conv2d(256, 512, 4 , padding = 1) , \n",
    "                    nn.InstanceNorm2d(512), \n",
    "                    nn.LeakyReLU(0.2 , inplace = True)]\n",
    "        \n",
    "        # FCN Classification layer\n",
    "        model += [  nn.Conv2d(512, 1 , 4 , padding = 1)]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self , x):\n",
    "        x = self.model(x)\n",
    "        # Average pooling and flatten\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0] , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2image(tensor):\n",
    "    image = 127.5 * (tensor[0].cpu().float().numpy() + 1.0)\n",
    "    if image.shape[0] == 1 :\n",
    "        image = np.tile(image , (3,1,1))\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__ (self,max_size = 50) : \n",
    "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful'\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "        \n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element,0)\n",
    "            if len(self.data) < self.max_size :\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else :\n",
    "                if random.uniform(0.1) > 0.5:\n",
    "                    i = random.randint(0 , self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else : \n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "    \n",
    "    class LambdaLR():\n",
    "        def __init__(self, n_epochs , offset , decay_start_epoch):\n",
    "            assert((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends !\"\n",
    "            self.n_epochs = n_epochs\n",
    "            self.offset = offset\n",
    "            self.decay_start_epoch = decay_start_epoch\n",
    "            \n",
    "        def step(self, epoch):\n",
    "            return 1.0 - max(0 , epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
    "    \n",
    "    def weights_init_normal(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            torch.nn.init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "\n",
    "epoch = 0\n",
    "n_epochs = 50\n",
    "batchSize = 1\n",
    "dataroot = './img_celeba/preprocessed_dataset_celeba/' \n",
    "lr = 0.0002\n",
    "decay_epoch = 3\n",
    "size = 256\n",
    "input_nc = 3\n",
    "output_nc = 3\n",
    "cuda = True\n",
    "n_cpu = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done for now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d8cd8638caa719e77c3ece9ee6c9cdab6f2065d170551d375a17b4273bc3a23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
