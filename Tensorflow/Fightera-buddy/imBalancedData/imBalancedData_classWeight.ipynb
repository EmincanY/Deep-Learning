{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples = 100000,\n",
    "                           n_features= 10,\n",
    "                           n_classes= 2,\n",
    "                           weights= [0.99, 0.01],\n",
    "                           n_redundant = 0)\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.bar(unique, counts)\n",
    "\n",
    "plt.xticks(unique, fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.title(\"Class Distribution\", fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size= 0.2 , stratify= y , random_state= 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5073438015271048, 1: 34.542314335060446}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight= 'balanced',\n",
    "                                     classes = [0, 1], # classes = np.unique(y_train)\n",
    "                                     y = y_train)\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                704       \n",
      "                                                                 \n",
      " tf.nn.relu (TFOpLambda)     (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " tf.nn.relu_1 (TFOpLambda)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,817\n",
      "Trainable params: 2,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.Input(shape=(X.shape[1],))\n",
    "\n",
    "x = tf.keras.layers.Dense(64)(input_layer)\n",
    "x = tf.nn.relu(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(32)(x)\n",
    "x = tf.nn.relu(x)\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "x = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "base_model = tf.keras.models.Model(input_layer, x)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model(np.expand_dims(X_train[0] ,axis = 0)) # You can call this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.16108054e-01,  2.71043032e-01,  1.08210772e-01,\n",
       "          1.31857395e-02, -1.68552458e-01,  1.36771411e-01,\n",
       "          1.30642802e-01,  1.28387392e-01, -2.66527325e-01,\n",
       "         -2.47259185e-01,  9.61025357e-02,  8.71491432e-03,\n",
       "          2.46217877e-01, -3.02383304e-02, -2.15522677e-01,\n",
       "          8.35797191e-03,  2.06997097e-01,  5.66520095e-02,\n",
       "         -1.00547850e-01, -2.71732301e-01, -1.50074482e-01,\n",
       "         -1.47621989e-01, -2.42859289e-01, -1.03544265e-01,\n",
       "         -3.74167860e-02,  1.91409022e-01, -2.49071479e-01,\n",
       "          2.08416730e-01,  1.35455877e-01,  2.30627745e-01,\n",
       "         -1.22295633e-01, -2.17682838e-01,  5.60192168e-02,\n",
       "          2.08862484e-01, -1.19528949e-01,  2.26035923e-01,\n",
       "         -1.52933300e-01,  1.16830170e-02, -2.42573619e-02,\n",
       "         -2.27973118e-01, -1.18794441e-02,  1.78072214e-01,\n",
       "         -2.74302244e-01,  1.55341446e-01,  2.49310225e-01,\n",
       "          1.87181771e-01,  2.16650456e-01, -1.55258775e-02,\n",
       "         -1.61515027e-01,  2.99145579e-02,  1.45407647e-01,\n",
       "         -1.01607934e-01, -2.37428784e-01, -2.42403835e-01,\n",
       "          2.19920248e-01,  9.88394916e-02, -4.65691239e-02,\n",
       "          2.52262950e-02, -1.95011497e-02,  2.83644289e-01,\n",
       "         -2.04588935e-01, -3.29650342e-02,  2.03057021e-01,\n",
       "         -2.10236356e-01],\n",
       "        [-2.33971730e-01,  1.25045210e-01, -1.25690907e-01,\n",
       "          2.47262210e-01, -1.88528836e-01, -1.54078379e-01,\n",
       "          2.41831392e-01, -1.33623943e-01, -2.29908362e-01,\n",
       "         -2.17216775e-01,  1.27586842e-01, -1.58287302e-01,\n",
       "         -2.20528334e-01, -3.97412479e-02,  1.61330849e-01,\n",
       "          2.44667739e-01, -1.03367269e-02,  1.13475889e-01,\n",
       "          2.54836231e-01,  2.48565078e-02,  1.39597028e-01,\n",
       "         -3.07941437e-02,  1.27415895e-01, -1.81859672e-01,\n",
       "          1.17074758e-01,  2.16558307e-01, -2.30313465e-01,\n",
       "          1.13627017e-01,  1.58726066e-01, -1.59272581e-01,\n",
       "         -5.46928644e-02,  2.54706532e-01, -1.63484007e-01,\n",
       "         -2.32434109e-01, -2.59621173e-01,  1.91301674e-01,\n",
       "         -1.91561639e-01, -2.55234301e-01, -2.29904905e-01,\n",
       "          2.41355270e-01,  1.53678864e-01,  2.28661746e-01,\n",
       "         -2.80007362e-01, -9.36702788e-02, -7.17603713e-02,\n",
       "          1.98400438e-01, -7.82191753e-03,  1.38268650e-01,\n",
       "          5.33391535e-02,  5.95549345e-02, -2.53137708e-01,\n",
       "          1.48716837e-01, -1.14379972e-01, -2.54129022e-01,\n",
       "          1.52472317e-01, -6.94224089e-02, -1.30724072e-01,\n",
       "         -1.95285678e-02, -4.86172587e-02,  2.01764137e-01,\n",
       "         -2.95898616e-02,  2.40589976e-02,  1.62818432e-02,\n",
       "          1.49156839e-01],\n",
       "        [ 5.21173477e-02, -2.44043276e-01,  2.64876574e-01,\n",
       "          1.72236800e-01, -1.94059759e-01,  2.46671945e-01,\n",
       "          1.81257308e-01, -3.50066572e-02, -2.81016082e-01,\n",
       "         -2.62288541e-01, -5.33481836e-02, -8.61783773e-02,\n",
       "         -1.10531747e-01, -6.30199909e-03,  5.34855127e-02,\n",
       "          2.65065998e-01,  7.70206153e-02,  5.32537401e-02,\n",
       "          2.23290414e-01,  2.44187623e-01,  4.17848527e-02,\n",
       "         -1.48947865e-01,  4.02357578e-02, -2.62566060e-01,\n",
       "         -1.60700291e-01, -2.26738021e-01,  1.51765674e-01,\n",
       "         -2.02722877e-01, -7.70236105e-02,  2.83175856e-01,\n",
       "         -2.59139419e-01, -2.29027301e-01, -2.05610812e-01,\n",
       "          1.53288156e-01, -2.16618270e-01,  2.40763336e-01,\n",
       "          1.72410607e-01,  1.98494792e-02,  1.80544317e-01,\n",
       "         -1.64467037e-01,  2.63416737e-01,  1.90511107e-01,\n",
       "          1.05626374e-01, -1.17910340e-01,  9.88696218e-02,\n",
       "         -2.46396378e-01, -3.40065062e-02,  2.17236847e-01,\n",
       "          2.48931617e-01,  3.52123678e-02, -2.63142854e-01,\n",
       "         -1.46250129e-02, -2.13481188e-01,  1.87639266e-01,\n",
       "         -7.46894479e-02, -6.07892275e-02,  2.21723586e-01,\n",
       "          5.73660731e-02,  2.07241416e-01, -9.40829068e-02,\n",
       "          2.42826432e-01,  8.29613209e-02,  2.20530778e-01,\n",
       "         -5.96806705e-02],\n",
       "        [ 2.41759121e-02,  9.19169188e-02,  4.09977436e-02,\n",
       "         -2.89961696e-02,  1.02451801e-01,  8.62956941e-02,\n",
       "          5.44981658e-02,  4.50372696e-04,  3.25262547e-03,\n",
       "         -3.34462523e-03,  2.55288988e-01,  2.48241127e-02,\n",
       "          1.34189248e-01,  1.84404492e-01,  2.63161093e-01,\n",
       "          2.06072122e-01, -1.95850521e-01,  1.10458225e-01,\n",
       "          5.10275960e-02, -2.53077209e-01,  1.68340117e-01,\n",
       "         -2.69719124e-01, -1.15758121e-01, -1.17734671e-02,\n",
       "         -2.80493319e-01, -1.63002267e-01,  9.69590247e-02,\n",
       "         -2.83047259e-01,  8.96699131e-02, -1.87041998e-01,\n",
       "         -2.69438058e-01,  2.03296065e-01,  2.29143649e-01,\n",
       "          1.96394533e-01, -1.89674377e-01,  2.22828299e-01,\n",
       "         -2.59733111e-01, -1.61976248e-01,  8.98270011e-02,\n",
       "          1.22185856e-01,  8.16966891e-02, -1.96174979e-01,\n",
       "          2.72401422e-01, -4.50124890e-02,  2.72751123e-01,\n",
       "         -2.55992979e-01,  1.47602856e-01, -2.27590427e-01,\n",
       "         -2.37261713e-01, -1.29499763e-01, -2.73340255e-01,\n",
       "          5.27179539e-02, -1.01087168e-01, -1.10091433e-01,\n",
       "          2.07333088e-01,  2.24889249e-01,  1.53520614e-01,\n",
       "          1.79530263e-01,  1.60476387e-01,  1.39542103e-01,\n",
       "          4.19712067e-02,  1.32310390e-02, -1.41605809e-01,\n",
       "          1.68181926e-01],\n",
       "        [ 8.57829154e-02,  2.79863089e-01, -7.57447779e-02,\n",
       "          1.68572485e-01,  9.88499522e-02,  6.05801344e-02,\n",
       "         -4.92580682e-02,  2.49098748e-01,  2.27082103e-01,\n",
       "          1.60147458e-01,  1.16310596e-01,  2.46547431e-01,\n",
       "          1.54426932e-01, -1.22851998e-01,  8.92238319e-02,\n",
       "         -7.03344345e-02, -2.28033200e-01,  1.35342628e-01,\n",
       "          5.71561456e-02,  1.17004097e-01, -7.30998963e-02,\n",
       "          8.85809660e-02, -1.04944959e-01, -1.10957086e-01,\n",
       "         -1.55357480e-01, -2.18846932e-01, -2.40446106e-01,\n",
       "          2.15855986e-01,  2.75046200e-01, -2.99403667e-02,\n",
       "          1.09389782e-01,  2.37128586e-01,  6.40969276e-02,\n",
       "          1.85036123e-01,  5.24953604e-02, -1.13192201e-02,\n",
       "          2.18520850e-01,  2.86212564e-03, -2.69223750e-02,\n",
       "          1.62853777e-01, -8.50138217e-02, -2.19524801e-02,\n",
       "          2.40106732e-01, -1.32800519e-01, -2.55923569e-02,\n",
       "         -2.68737108e-01, -2.01336712e-01, -2.16882020e-01,\n",
       "          2.60459870e-01, -2.18009353e-02, -2.70226061e-01,\n",
       "         -5.44757545e-02,  1.47861838e-02,  1.41448647e-01,\n",
       "          1.23075426e-01,  4.48457003e-02,  2.27461010e-01,\n",
       "         -7.11004287e-02, -2.11262286e-01, -1.95183516e-01,\n",
       "         -8.04687738e-02, -2.57877380e-01, -2.82326609e-01,\n",
       "         -2.21974045e-01],\n",
       "        [ 6.12642467e-02,  5.48413396e-03,  1.42909408e-01,\n",
       "         -2.36728236e-01,  1.69058025e-01, -8.22610557e-02,\n",
       "         -2.49089882e-01,  6.45935237e-02,  8.50003064e-02,\n",
       "         -4.55199629e-02, -2.80653536e-01, -9.03451443e-02,\n",
       "          2.06287593e-01, -6.41706586e-03,  1.49540484e-01,\n",
       "         -5.29467463e-02, -5.99654615e-02,  2.40290374e-01,\n",
       "         -4.82617319e-02,  2.13793814e-01,  1.40083998e-01,\n",
       "         -1.95396274e-01, -2.56747007e-02,  2.75437683e-01,\n",
       "          1.12951458e-01, -2.76309878e-01,  1.44993454e-01,\n",
       "         -2.80093998e-01,  3.64533663e-02, -2.50351608e-01,\n",
       "          2.46358544e-01, -2.43589446e-01, -1.36640131e-01,\n",
       "         -4.41662520e-02, -1.40756920e-01, -2.84053981e-01,\n",
       "          2.10617900e-01, -7.96421617e-02,  8.46582651e-03,\n",
       "         -2.18524128e-01,  1.44553602e-01,  2.31922776e-01,\n",
       "          8.02583098e-02, -2.74145156e-01,  1.22726053e-01,\n",
       "         -1.26529634e-02, -2.55953610e-01,  1.35426283e-01,\n",
       "         -1.58501625e-01, -2.28943050e-01,  2.59656698e-01,\n",
       "          1.53493911e-01,  1.47120506e-01, -6.70777261e-02,\n",
       "         -2.58339703e-01,  2.32780725e-01, -2.48914450e-01,\n",
       "          8.19079578e-02, -1.69837743e-01, -7.43581504e-02,\n",
       "          7.07594156e-02, -5.61520606e-02, -8.76255035e-02,\n",
       "         -1.36197418e-01],\n",
       "        [-1.86969891e-01,  1.05506390e-01,  2.14412004e-01,\n",
       "         -7.29725361e-02,  1.30471587e-01,  2.48552829e-01,\n",
       "         -2.17998713e-01, -5.84272295e-02, -1.39419138e-02,\n",
       "          7.68875480e-02, -1.73979938e-01,  1.28147691e-01,\n",
       "         -1.87531531e-01,  1.09740704e-01, -5.37665188e-02,\n",
       "          1.50157809e-02, -2.16330081e-01, -2.80583471e-01,\n",
       "          2.73698777e-01,  8.93608332e-02,  2.64350504e-01,\n",
       "         -1.19952455e-01, -2.72560418e-02,  2.18530923e-01,\n",
       "          2.04941630e-02,  2.17948407e-01, -1.53227255e-01,\n",
       "         -1.99361473e-01, -3.66241187e-02,  6.89378083e-02,\n",
       "          2.03651935e-01, -1.41253322e-01,  2.01918513e-01,\n",
       "         -2.46444315e-01,  2.63647825e-01,  3.93203199e-02,\n",
       "         -4.56387699e-02,  2.39558011e-01,  1.87771738e-01,\n",
       "         -1.58286348e-01,  8.15534294e-02, -1.61151946e-01,\n",
       "         -7.41461962e-02,  1.92971826e-02, -1.93957850e-01,\n",
       "          1.10982955e-01, -1.37260228e-01,  1.41095817e-01,\n",
       "         -2.03064963e-01,  2.17340022e-01,  2.98784673e-02,\n",
       "         -1.55307993e-01, -2.65822172e-01,  1.00018978e-02,\n",
       "         -1.22278258e-01, -2.07952842e-01,  1.62342101e-01,\n",
       "         -1.88763246e-01,  2.41358608e-01, -1.42084762e-01,\n",
       "         -2.05675572e-01,  3.06586921e-02, -1.04039922e-01,\n",
       "         -1.78145260e-01],\n",
       "        [ 2.64467925e-01, -3.90217602e-02, -9.82079208e-02,\n",
       "          8.79754722e-02,  2.75981396e-01,  2.70430237e-01,\n",
       "         -1.32600188e-01,  1.96579993e-01, -2.36641467e-01,\n",
       "         -1.86552033e-01,  3.47891450e-03, -2.76138991e-01,\n",
       "          2.84034103e-01, -1.54265627e-01,  2.34791547e-01,\n",
       "          2.72032917e-02, -9.30133462e-03,  1.87877893e-01,\n",
       "         -1.49103329e-01,  7.57563114e-02,  2.32944459e-01,\n",
       "          2.57794708e-01,  1.01945758e-01,  2.22171038e-01,\n",
       "          1.87985241e-01,  1.50770217e-01,  1.27726823e-01,\n",
       "         -6.55435622e-02, -1.89814240e-01,  2.61373132e-01,\n",
       "         -1.56901479e-01,  2.60812372e-01, -1.24758661e-01,\n",
       "          1.17496431e-01,  1.86129004e-01,  1.76601410e-01,\n",
       "         -1.33288503e-01, -1.80939510e-01, -2.69213140e-01,\n",
       "         -9.80052054e-02,  1.92620218e-01, -2.37455666e-01,\n",
       "         -2.46846616e-01, -2.21291542e-01, -2.32292086e-01,\n",
       "          5.53722382e-02,  1.66305542e-01,  1.44451708e-01,\n",
       "         -8.54447037e-02, -2.16047466e-01,  2.51532644e-01,\n",
       "         -2.01895297e-01, -2.17799664e-01,  4.49948311e-02,\n",
       "         -7.66330510e-02, -2.70622998e-01, -2.50119001e-01,\n",
       "         -2.81414181e-01,  8.18469226e-02, -1.13707125e-01,\n",
       "         -7.13287294e-02, -1.50595129e-01,  4.92349267e-02,\n",
       "         -1.35814726e-01],\n",
       "        [ 1.28688961e-01, -4.01977301e-02, -2.69977152e-02,\n",
       "         -8.05090368e-02, -4.32352275e-02,  7.28076398e-02,\n",
       "          1.46819681e-01,  6.46113157e-02,  5.42284846e-02,\n",
       "          2.15479165e-01,  1.76727116e-01, -2.46101916e-02,\n",
       "          1.34506792e-01,  2.90728211e-02,  1.37805372e-01,\n",
       "         -1.19446874e-01,  4.19536233e-02, -2.71886587e-04,\n",
       "         -1.77996650e-01, -9.30547267e-02,  2.09733576e-01,\n",
       "         -2.78520674e-01,  2.26199597e-01,  2.49111205e-01,\n",
       "         -2.37311125e-01,  1.47687167e-01,  1.30442083e-02,\n",
       "          1.32257342e-02,  2.48031169e-01,  1.23998493e-01,\n",
       "          3.71632874e-02,  1.66369438e-01, -1.96179152e-02,\n",
       "         -1.15244821e-01, -6.20217621e-02, -1.75748229e-01,\n",
       "         -1.52379125e-01, -5.07229716e-02, -6.22231811e-02,\n",
       "         -6.64485991e-02,  1.25234008e-01, -2.13797614e-01,\n",
       "         -2.16440469e-01,  8.98689032e-02,  8.25103521e-02,\n",
       "          2.67345935e-01,  1.89537734e-01,  2.31403440e-01,\n",
       "          6.44763410e-02, -1.33946076e-01, -5.98139316e-02,\n",
       "          8.41813684e-02, -2.53053308e-01,  1.50603354e-01,\n",
       "         -1.66273639e-01, -2.67707378e-01, -1.46552950e-01,\n",
       "          2.66271025e-01,  1.81896746e-01,  2.38512546e-01,\n",
       "         -2.62368649e-01, -1.26316443e-01,  1.53851211e-01,\n",
       "          2.62296468e-01],\n",
       "        [-5.56753427e-02, -1.07781500e-01, -2.69804180e-01,\n",
       "          1.30002886e-01,  1.43196851e-01, -3.08119953e-02,\n",
       "          1.77356601e-01,  1.30540490e-01, -1.04743257e-01,\n",
       "         -1.55842617e-01, -1.10943571e-01,  1.59550518e-01,\n",
       "          2.39518255e-01, -5.93780875e-02, -8.48153085e-02,\n",
       "         -4.80973721e-03,  2.04254776e-01,  1.56167179e-01,\n",
       "          1.26827657e-01, -1.32297799e-01,  2.33226091e-01,\n",
       "         -1.89390272e-01, -6.73955083e-02,  2.70385116e-01,\n",
       "         -1.97648093e-01,  6.45946860e-02,  1.77025348e-01,\n",
       "          2.60743707e-01,  7.88895488e-02,  7.38827884e-02,\n",
       "         -2.65481234e-01,  6.92768693e-02,  1.62037820e-01,\n",
       "          2.97987461e-02, -1.31244034e-01, -2.17880726e-01,\n",
       "         -2.31722981e-01, -2.26210594e-01,  2.45101184e-01,\n",
       "          5.15555143e-02, -2.44655982e-01,  2.58665353e-01,\n",
       "         -2.70228565e-01,  1.43014491e-02,  8.22003484e-02,\n",
       "         -4.64961976e-02,  2.44913012e-01,  2.12882459e-02,\n",
       "          2.64517754e-01, -1.61607265e-02,  4.89522219e-02,\n",
       "          2.19235420e-02,  8.54715705e-03, -8.60744715e-03,\n",
       "          1.76074177e-01,  1.11256272e-01, -1.64399892e-01,\n",
       "          1.51384264e-01,  1.89894825e-01, -2.35532492e-01,\n",
       "         -1.51608855e-01, -2.16916502e-02, -2.13552669e-01,\n",
       "          7.53458738e-02]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.24090624, -0.12772655, -0.24993724, ..., -0.21731806,\n",
       "          0.03085029, -0.24542892],\n",
       "        [ 0.17423403, -0.12493563, -0.14239973, ...,  0.03963804,\n",
       "          0.12126613,  0.04770434],\n",
       "        [-0.12512428, -0.11861807,  0.17763317, ..., -0.05629545,\n",
       "          0.17273587, -0.08634198],\n",
       "        ...,\n",
       "        [-0.10888076, -0.08751541,  0.21187979, ..., -0.24967921,\n",
       "         -0.1414091 ,  0.22126561],\n",
       "        [-0.22025609, -0.19196773, -0.23976648, ...,  0.23885417,\n",
       "          0.06771272, -0.23299092],\n",
       "        [-0.14620167, -0.09370154, -0.22842187, ..., -0.08979887,\n",
       "         -0.21774781, -0.18154687]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[ 0.0288949 ],\n",
       "        [-0.1031464 ],\n",
       "        [-0.41571411],\n",
       "        [-0.14915973],\n",
       "        [ 0.24738455],\n",
       "        [-0.38769656],\n",
       "        [-0.15733641],\n",
       "        [ 0.1321398 ],\n",
       "        [ 0.39548135],\n",
       "        [ 0.16785723],\n",
       "        [ 0.21553373],\n",
       "        [ 0.2582602 ],\n",
       "        [ 0.15570009],\n",
       "        [-0.1017468 ],\n",
       "        [-0.18569057],\n",
       "        [-0.15773931],\n",
       "        [-0.17652604],\n",
       "        [ 0.00520539],\n",
       "        [ 0.07361609],\n",
       "        [-0.17953402],\n",
       "        [-0.11111709],\n",
       "        [-0.12345684],\n",
       "        [ 0.02890942],\n",
       "        [-0.08562627],\n",
       "        [ 0.4148876 ],\n",
       "        [-0.30909413],\n",
       "        [-0.07591969],\n",
       "        [ 0.1888597 ],\n",
       "        [-0.32906687],\n",
       "        [ 0.12982178],\n",
       "        [ 0.36896056],\n",
       "        [ 0.18283784]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save_weights(\"initial_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_model = tf.keras.models.clone_model(base_model)\n",
    "focal_loss_model = tf.keras.models.clone_model(base_model)\n",
    "cat_focal_loss_model = tf.keras.models.clone_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(optimizer = 'adam',\n",
    "                   loss = 'binary_crossentropy',\n",
    "                   metrics = [tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "500/500 [==============================] - 2s 2ms/step - loss: 0.1072 - precision: 0.0122 - recall: 0.0118 - val_loss: 0.0608 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0657 - precision: 0.3333 - recall: 0.0224 - val_loss: 0.0582 - val_precision: 0.5000 - val_recall: 0.0405\n",
      "Epoch 3/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0635 - precision: 0.4174 - recall: 0.0513 - val_loss: 0.0573 - val_precision: 0.5000 - val_recall: 0.0541\n",
      "Epoch 4/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0620 - precision: 0.4336 - recall: 0.0524 - val_loss: 0.0558 - val_precision: 0.4884 - val_recall: 0.0946\n",
      "Epoch 5/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0610 - precision: 0.5197 - recall: 0.0705 - val_loss: 0.0558 - val_precision: 0.5806 - val_recall: 0.0811\n",
      "Epoch 6/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0605 - precision: 0.5652 - recall: 0.0694 - val_loss: 0.0544 - val_precision: 0.7241 - val_recall: 0.0946\n",
      "Epoch 7/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0597 - precision: 0.6759 - recall: 0.0780 - val_loss: 0.0538 - val_precision: 0.8214 - val_recall: 0.1036\n",
      "Epoch 8/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0589 - precision: 0.8174 - recall: 0.1004 - val_loss: 0.0536 - val_precision: 0.9231 - val_recall: 0.1081\n",
      "Epoch 9/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0572 - precision: 0.8409 - recall: 0.1186 - val_loss: 0.0523 - val_precision: 0.9211 - val_recall: 0.1577\n",
      "Epoch 10/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0561 - precision: 0.8741 - recall: 0.1335 - val_loss: 0.0510 - val_precision: 0.9302 - val_recall: 0.1802\n",
      "Epoch 11/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0554 - precision: 0.9023 - recall: 0.1677 - val_loss: 0.0507 - val_precision: 0.8824 - val_recall: 0.2027\n",
      "Epoch 12/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0543 - precision: 0.9006 - recall: 0.1741 - val_loss: 0.0496 - val_precision: 0.9318 - val_recall: 0.1847\n",
      "Epoch 13/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0536 - precision: 0.8810 - recall: 0.1976 - val_loss: 0.0490 - val_precision: 0.9545 - val_recall: 0.1892\n",
      "Epoch 14/32\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.0534 - precision: 0.8500 - recall: 0.2179 - val_loss: 0.0488 - val_precision: 0.9574 - val_recall: 0.2027\n",
      "Epoch 15/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0533 - precision: 0.8445 - recall: 0.2147 - val_loss: 0.0479 - val_precision: 0.9583 - val_recall: 0.2072\n",
      "Epoch 16/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0522 - precision: 0.8340 - recall: 0.2361 - val_loss: 0.0478 - val_precision: 0.9444 - val_recall: 0.2297\n",
      "Epoch 17/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0516 - precision: 0.8045 - recall: 0.2286 - val_loss: 0.0477 - val_precision: 0.9574 - val_recall: 0.2027\n",
      "Epoch 18/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0520 - precision: 0.8527 - recall: 0.2350 - val_loss: 0.0477 - val_precision: 0.9206 - val_recall: 0.2613\n",
      "Epoch 19/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0514 - precision: 0.8000 - recall: 0.2436 - val_loss: 0.0470 - val_precision: 0.9265 - val_recall: 0.2838\n",
      "Epoch 20/32\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.0510 - precision: 0.8333 - recall: 0.2404 - val_loss: 0.0469 - val_precision: 0.9206 - val_recall: 0.2613\n",
      "Epoch 21/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0512 - precision: 0.7814 - recall: 0.2329 - val_loss: 0.0470 - val_precision: 0.9138 - val_recall: 0.2387\n",
      "Epoch 22/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0505 - precision: 0.8401 - recall: 0.2415 - val_loss: 0.0464 - val_precision: 0.8442 - val_recall: 0.2928\n",
      "Epoch 23/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0503 - precision: 0.8322 - recall: 0.2596 - val_loss: 0.0465 - val_precision: 0.9143 - val_recall: 0.2883\n",
      "Epoch 24/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0499 - precision: 0.8282 - recall: 0.2575 - val_loss: 0.0467 - val_precision: 0.8750 - val_recall: 0.2838\n",
      "Epoch 25/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0499 - precision: 0.8292 - recall: 0.2489 - val_loss: 0.0475 - val_precision: 0.7912 - val_recall: 0.3243\n",
      "Epoch 26/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0497 - precision: 0.7816 - recall: 0.2639 - val_loss: 0.0460 - val_precision: 0.8675 - val_recall: 0.3243\n",
      "Epoch 27/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0500 - precision: 0.8020 - recall: 0.2511 - val_loss: 0.0463 - val_precision: 0.9153 - val_recall: 0.2432\n",
      "Epoch 28/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0497 - precision: 0.8153 - recall: 0.2500 - val_loss: 0.0460 - val_precision: 0.8611 - val_recall: 0.2793\n",
      "Epoch 29/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0495 - precision: 0.8163 - recall: 0.2564 - val_loss: 0.0463 - val_precision: 0.8214 - val_recall: 0.3108\n",
      "Epoch 30/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0492 - precision: 0.8034 - recall: 0.2532 - val_loss: 0.0459 - val_precision: 0.9365 - val_recall: 0.2658\n",
      "Epoch 31/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0492 - precision: 0.8275 - recall: 0.2511 - val_loss: 0.0462 - val_precision: 0.9155 - val_recall: 0.2928\n",
      "Epoch 32/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0487 - precision: 0.8050 - recall: 0.2735 - val_loss: 0.0457 - val_precision: 0.8488 - val_recall: 0.3288\n"
     ]
    }
   ],
   "source": [
    "history = base_model.fit(X_train, y_train, epochs = 32, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step - loss: 0.0499 - precision: 0.7679 - recall: 0.2966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04988572746515274, 0.7678571343421936, 0.29655173420906067]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 465us/step\n"
     ]
    }
   ],
   "source": [
    "preds = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     19710\n",
      "           1       0.77      0.30      0.43       290\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.88      0.65      0.71     20000\n",
      "weighted avg       0.99      0.99      0.99     20000\n",
      "\n",
      "[[19684    26]\n",
      " [  204    86]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_pred = np.where(preds >= threshold , 1 , 0)\n",
    "\n",
    "print(classification_report(y_test,  y_pred))\n",
    "print(confusion_matrix(y_test,  y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     19710\n",
      "           1       0.38      0.50      0.43       290\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.69      0.75      0.71     20000\n",
      "weighted avg       0.98      0.98      0.98     20000\n",
      "\n",
      "[[19473   237]\n",
      " [  144   146]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "y_pred = np.where(preds >= threshold , 1 , 0)\n",
    "\n",
    "print(classification_report(y_test,  y_pred))\n",
    "print(confusion_matrix(y_test,  y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_model.load_weights(\"initial_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5073438015271048, 1: 34.542314335060446}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5463 - precision_1: 0.0463 - recall_1: 0.6752 - val_loss: 0.5131 - val_precision_1: 0.0571 - val_recall_1: 0.7162\n",
      "Epoch 2/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5009 - precision_1: 0.0699 - recall_1: 0.6645 - val_loss: 0.4604 - val_precision_1: 0.0724 - val_recall_1: 0.6982\n",
      "Epoch 3/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4950 - precision_1: 0.0780 - recall_1: 0.6741 - val_loss: 0.4848 - val_precision_1: 0.0770 - val_recall_1: 0.7072\n",
      "Epoch 4/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4869 - precision_1: 0.0810 - recall_1: 0.6763 - val_loss: 0.3995 - val_precision_1: 0.0898 - val_recall_1: 0.6577\n",
      "Epoch 5/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4863 - precision_1: 0.0867 - recall_1: 0.6795 - val_loss: 0.4274 - val_precision_1: 0.0834 - val_recall_1: 0.6802\n",
      "Epoch 6/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4806 - precision_1: 0.0871 - recall_1: 0.6774 - val_loss: 0.4800 - val_precision_1: 0.0787 - val_recall_1: 0.7027\n",
      "Epoch 7/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4777 - precision_1: 0.0888 - recall_1: 0.6838 - val_loss: 0.4791 - val_precision_1: 0.0781 - val_recall_1: 0.7072\n",
      "Epoch 8/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4738 - precision_1: 0.0878 - recall_1: 0.6880 - val_loss: 0.4427 - val_precision_1: 0.0868 - val_recall_1: 0.6667\n",
      "Epoch 9/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4684 - precision_1: 0.0923 - recall_1: 0.6912 - val_loss: 0.4480 - val_precision_1: 0.0825 - val_recall_1: 0.6712\n",
      "Epoch 10/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4689 - precision_1: 0.0911 - recall_1: 0.6880 - val_loss: 0.4174 - val_precision_1: 0.0916 - val_recall_1: 0.6712\n",
      "Epoch 11/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4641 - precision_1: 0.0943 - recall_1: 0.6934 - val_loss: 0.4819 - val_precision_1: 0.0822 - val_recall_1: 0.6982\n",
      "Epoch 12/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4615 - precision_1: 0.0954 - recall_1: 0.6944 - val_loss: 0.4270 - val_precision_1: 0.0870 - val_recall_1: 0.6757\n",
      "Epoch 13/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4596 - precision_1: 0.0967 - recall_1: 0.6923 - val_loss: 0.4685 - val_precision_1: 0.0796 - val_recall_1: 0.7027\n",
      "Epoch 14/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4563 - precision_1: 0.0937 - recall_1: 0.6923 - val_loss: 0.4174 - val_precision_1: 0.0904 - val_recall_1: 0.6802\n",
      "Epoch 15/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4535 - precision_1: 0.0958 - recall_1: 0.6934 - val_loss: 0.4392 - val_precision_1: 0.0842 - val_recall_1: 0.6937\n",
      "Epoch 16/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4542 - precision_1: 0.0952 - recall_1: 0.7019 - val_loss: 0.4613 - val_precision_1: 0.0788 - val_recall_1: 0.6937\n",
      "Epoch 17/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4495 - precision_1: 0.0918 - recall_1: 0.7051 - val_loss: 0.3689 - val_precision_1: 0.1019 - val_recall_1: 0.6622\n",
      "Epoch 18/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4473 - precision_1: 0.0978 - recall_1: 0.6998 - val_loss: 0.3904 - val_precision_1: 0.0936 - val_recall_1: 0.6757\n",
      "Epoch 19/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4455 - precision_1: 0.0957 - recall_1: 0.6998 - val_loss: 0.4311 - val_precision_1: 0.0852 - val_recall_1: 0.6982\n",
      "Epoch 20/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4409 - precision_1: 0.0961 - recall_1: 0.6998 - val_loss: 0.4408 - val_precision_1: 0.0813 - val_recall_1: 0.7027\n",
      "Epoch 21/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4343 - precision_1: 0.0956 - recall_1: 0.7051 - val_loss: 0.4509 - val_precision_1: 0.0798 - val_recall_1: 0.7027\n",
      "Epoch 22/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4396 - precision_1: 0.0921 - recall_1: 0.7030 - val_loss: 0.4363 - val_precision_1: 0.0809 - val_recall_1: 0.6982\n",
      "Epoch 23/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4351 - precision_1: 0.0927 - recall_1: 0.7126 - val_loss: 0.4235 - val_precision_1: 0.0811 - val_recall_1: 0.6937\n",
      "Epoch 24/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4308 - precision_1: 0.0950 - recall_1: 0.7201 - val_loss: 0.3922 - val_precision_1: 0.0917 - val_recall_1: 0.6847\n",
      "Epoch 25/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4312 - precision_1: 0.0936 - recall_1: 0.7179 - val_loss: 0.4292 - val_precision_1: 0.0784 - val_recall_1: 0.7162\n",
      "Epoch 26/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4281 - precision_1: 0.0933 - recall_1: 0.7147 - val_loss: 0.4477 - val_precision_1: 0.0798 - val_recall_1: 0.7117\n",
      "Epoch 27/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4238 - precision_1: 0.0936 - recall_1: 0.7158 - val_loss: 0.3380 - val_precision_1: 0.1010 - val_recall_1: 0.6667\n",
      "Epoch 28/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4229 - precision_1: 0.0956 - recall_1: 0.7169 - val_loss: 0.3769 - val_precision_1: 0.0893 - val_recall_1: 0.6757\n",
      "Epoch 29/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4200 - precision_1: 0.0933 - recall_1: 0.7254 - val_loss: 0.3730 - val_precision_1: 0.0900 - val_recall_1: 0.6892\n",
      "Epoch 30/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4143 - precision_1: 0.0914 - recall_1: 0.7244 - val_loss: 0.4408 - val_precision_1: 0.0759 - val_recall_1: 0.7252\n",
      "Epoch 31/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4070 - precision_1: 0.0939 - recall_1: 0.7350 - val_loss: 0.3392 - val_precision_1: 0.0959 - val_recall_1: 0.6937\n",
      "Epoch 32/32\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4150 - precision_1: 0.0949 - recall_1: 0.7286 - val_loss: 0.4124 - val_precision_1: 0.0855 - val_recall_1: 0.7117\n"
     ]
    }
   ],
   "source": [
    "class_weight_model.compile(optimizer = 'adam',\n",
    "                   loss = 'binary_crossentropy',\n",
    "                   metrics = [tf.keras.metrics.Precision(),\n",
    "                              tf.keras.metrics.Recall()])\n",
    "\n",
    "\n",
    "history_cw = class_weight_model.fit(X_train, y_train, \n",
    "                         epochs = 32, \n",
    "                         batch_size= 128, \n",
    "                         validation_split= 0.2,\n",
    "                         class_weight= class_weights)\n",
    "                        # class_weight= {0: 0.5, 1: 32.948929159802304})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 449us/step\n"
     ]
    }
   ],
   "source": [
    "preds = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     19710\n",
      "           1       0.77      0.30      0.43       290\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.88      0.65      0.71     20000\n",
      "weighted avg       0.99      0.99      0.99     20000\n",
      "\n",
      "[[19684    26]\n",
      " [  204    86]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_pred = np.where(preds >= threshold , 1 , 0)\n",
    "\n",
    "print(classification_report(y_test,  y_pred))\n",
    "print(confusion_matrix(y_test,  y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     19710\n",
      "           1       0.38      0.50      0.43       290\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.69      0.75      0.71     20000\n",
      "weighted avg       0.98      0.98      0.98     20000\n",
      "\n",
      "[[19473   237]\n",
      " [  144   146]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "y_pred = np.where(preds >= threshold , 1 , 0)\n",
    "\n",
    "print(classification_report(y_test,  y_pred))\n",
    "print(confusion_matrix(y_test,  y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     19710\n",
      "           1       0.10      0.66      0.18       290\n",
      "\n",
      "    accuracy                           0.91     20000\n",
      "   macro avg       0.55      0.79      0.57     20000\n",
      "weighted avg       0.98      0.91      0.94     20000\n",
      "\n",
      "[[18081  1629]\n",
      " [   99   191]]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.02\n",
    "y_pred = np.where(preds >= threshold , 1 , 0)\n",
    "\n",
    "print(classification_report(y_test,  y_pred))\n",
    "print(confusion_matrix(y_test,  y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done for now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
